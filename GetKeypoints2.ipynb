{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f938abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\amarb\\appdata\\roaming\\python\\python39\\site-packages (0.9.0.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\amarb\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: matplotlib in d:\\installs\\anaconda\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\installs\\anaconda\\lib\\site-packages (from mediapipe) (3.19.6)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\installs\\anaconda\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: numpy in d:\\installs\\anaconda\\lib\\site-packages (from mediapipe) (1.20.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\amarb\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (1.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\amarb\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (22.12.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\installs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\installs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\installs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\installs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\installs\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: six in d:\\installs\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setup the Pose function for images - independently for the images standalone processing.\n",
    "pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.8,model_complexity=2)\n",
    "\n",
    "# Setup the Pose function for videos - for video processing.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7,\n",
    "                          min_tracking_confidence=0.7)\n",
    "\n",
    "# Initialize mediapipe drawing class - to draw the landmarks points.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "def mpPoseImg(image_pose, pose=pose_image, draw=False, display=False):\n",
    "    \n",
    "    annotated_image = image_pose.copy()\n",
    "    \n",
    "    image_in_RGB = cv2.cvtColor(image_pose, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    \n",
    "    results = pose.process(image_in_RGB)\n",
    "\n",
    "    if results.pose_landmarks and draw:    \n",
    "      mp_drawing.draw_landmarks(image=annotated_image,landmark_list=results.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n",
    "                                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "\n",
    "        # mp_drawing.draw_landmarks(image=original_image, landmark_list=resultant.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n",
    "        #                           landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),thickness=3, circle_radius=3),\n",
    "        #                           connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),thickness=2, circle_radius=2))\n",
    "\n",
    "    if display:\n",
    "            \n",
    "            # plt.figure(figsize=[22,22])\n",
    "            # plt.subplot(121);plt.imshow(image_pose[:,:,::-1]);plt.title(\"Input Image\");plt.axis('off');\n",
    "            # plt.subplot(122);plt.imshow(annotated_image[:,:,::-1]);plt.title(\"Pose detected Image\");plt.axis('off');\n",
    "            cv2.imshow(annotated_image)\n",
    "            return results\n",
    "\n",
    "    else:\n",
    "        return annotated_image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df1102a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BODY_PARTS = {\n",
    "#     0: 'nose', 1: 'left_eye_inner', 2: 'left_eye', 3: 'left_eye_outer', 4: 'right_eye_inner', 5: 'right_eye', 6: 'right_eye_outer', 7: 'left_ear', 8: 'right_ear',\n",
    "#     9: 'mouth_left', 10: 'mouth_right', 11: 'left_shoulder', 12: 'right_shoulder', 13: 'left_elbow', 14: 'right_elbow', 15: 'left_wrist',16: 'right_wrist',\n",
    "#     17: 'left_pinky_finger', 18: 'right_pinky_finger', 19: 'left_index_finger', 20: 'right_index_finger', 21: 'left_thumb', 22: 'right_thumb', 23: 'left_hip', 24: 'right_hip',\n",
    "#     25: 'left_knee', 26: 'right_knee', 27: 'left_ankle', 28: 'right_ankle', 29: 'left_heel', 30: 'right_heel', 31: 'left_foot_index', 32: 'right_foot_index', 33: 'mid_hip', 34: 'neck'\n",
    "# }\n",
    "\n",
    "BODY_PARTS = {0: 'NOSE',\n",
    "              1: 'LEFT_EYE_INNER',\n",
    "              2: 'LEFT_EYE',\n",
    "              3: 'LEFT_EYE_OUTER',\n",
    "              4: 'RIGHT_EYE_INNER',\n",
    "              5: 'RIGHT_EYE',\n",
    "              6: 'RIGHT_EYE_OUTER',\n",
    "              7: 'LEFT_EAR',\n",
    "              8: 'RIGHT_EAR',\n",
    "              9: 'MOUTH_LEFT',\n",
    "              10: 'MOUTH_RIGHT',\n",
    "              11: 'LEFT_SHOULDER',\n",
    "              12: 'RIGHT_SHOULDER',\n",
    "              13: 'LEFT_ELBOW',\n",
    "              14: 'RIGHT_ELBOW',\n",
    "              15: 'LEFT_WRIST',\n",
    "              16: 'RIGHT_WRIST',\n",
    "              17: 'LEFT_PINKY',\n",
    "              18: 'RIGHT_PINKY',\n",
    "              19: 'LEFT_INDEX',\n",
    "              20: 'RIGHT_INDEX',\n",
    "              21: 'LEFT_THUMB',\n",
    "              22: 'RIGHT_THUMB',\n",
    "              23: 'LEFT_HIP',\n",
    "              24: 'RIGHT_HIP',\n",
    "              25: 'LEFT_KNEE',\n",
    "              26: 'RIGHT_KNEE',\n",
    "              27: 'LEFT_ANKLE',\n",
    "              28: 'RIGHT_ANKLE',\n",
    "              29: 'LEFT_HEEL',\n",
    "              30: 'RIGHT_HEEL',\n",
    "              31: 'LEFT_FOOT_INDEX',\n",
    "              32: 'RIGHT_FOOT_INDEX',\n",
    "              33: 'MID_HIP',\n",
    "              34: 'NECK'}\n",
    "\n",
    "BODY_PARTS_DICT = {value: key for key, value in BODY_PARTS.items()}\n",
    "\n",
    "# Define the groups of keypoints by body parts\n",
    "keypoint_groups = {\n",
    "     0:[1,2,3,4,5,6,7,8],\n",
    "     1:[0,2,3,4,5,6],\n",
    "     2:[0,1,3,4,5,6],\n",
    "     3:[0,1,2,4,5,6],\n",
    "     4:[0,1,2,3,5,6],\n",
    "     5:[0,1,2,3,4,6],\n",
    "     6:[0,1,2,3,4,5],\n",
    "     7:[0,1,2,3,9],\n",
    "     8:[0,4,5,6,10],\n",
    "     9:[0,7,10],\n",
    "     10:[0,8,9],\n",
    "     11:[12,13,9],\n",
    "     12:[11,14,10],\n",
    "     13:[11,15],\n",
    "     14:[12,16],\n",
    "     15:[13,17,19],\n",
    "     16:[14,18,20],\n",
    "     17:[15,19,21],\n",
    "     18:[16,20,22],\n",
    "     19:[15,17,21],\n",
    "     20:[16,18,22],\n",
    "     21:[17,19],\n",
    "     22:[18,20],\n",
    "     23:[24,25],\n",
    "     24:[23,26],\n",
    "     25:[23,27],\n",
    "     26:[24,28],\n",
    "     27:[25,29,31],\n",
    "     28:[26,30,32],\n",
    "     29:[27,31],\n",
    "     30:[28,32],\n",
    "     31:[27,29],\n",
    "     32:[28,30],\n",
    "     33:[23,24],\n",
    "     34:[11,12]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "decaa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplacebyAverage(index,keypoints):\n",
    "  group_indices = keypoint_groups[index]\n",
    "  group_keypoints = [keypoints[i] for i in group_indices]\n",
    "  valid_keypoints = [k for k in group_keypoints if k is not None]\n",
    "  if len(valid_keypoints) > 0:\n",
    "     group_average_x = np.mean([k[0] for k in valid_keypoints if k[0] is not None])\n",
    "     group_average_y = np.mean([k[1] for k in valid_keypoints if k[1] is not None])\n",
    "    #  keypoints[index][0]=group_average_x\n",
    "    #  keypoints[index][1]=group_average_y\n",
    "  else:\n",
    "    # If all keypoints in the group are missing, replace with (0,0) or another default value\n",
    "    group_average_x, group_average_y = 0, 0\n",
    "  return [group_average_x,group_average_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0b42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReplaceNonebyAverage(keypoints):\n",
    "  group_indices = keypoint_groups[index]\n",
    "  group_keypoints = [keypoints[i] for i in group_indices]\n",
    "  \n",
    "  if len(valid_keypoints) > 0:\n",
    "     group_average_x = np.mean([k[0] for k in valid_keypoints if k[0] is not None])\n",
    "     group_average_y = np.mean([k[1] for k in valid_keypoints if k[1] is not None])\n",
    "    #  keypoints[index][0]=group_average_x\n",
    "    #  keypoints[index][1]=group_average_y\n",
    "  else:\n",
    "    # If all keypoints in the group are missing, replace with (0,0) or another default value\n",
    "    group_average_x, group_average_y = 0, 0\n",
    "  return [group_average_x,group_average_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a931a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the center of the object in each frame\n",
    "def CentralisedKeypoints1(keypoints, live = False):\n",
    "  frame_centers = []\n",
    " \n",
    "  for frame_keypoints in keypoints:\n",
    "    # assume the center is the mean of all keypoints\n",
    "    center_x = np.nanmean([kp[0] for kp in frame_keypoints if kp[0] is not None])\n",
    "    center_y = np.nanmean([kp[1] for kp in frame_keypoints if kp[1] is not None])\n",
    "    frame_centers.append((center_x, center_y))\n",
    "\n",
    "  relative_keypoints = keypoints\n",
    "\n",
    "  for j in range(len(relative_keypoints)):               #frame no\n",
    "    for k in range(len(relative_keypoints[j])):          # each keypoint of frame\n",
    "      if relative_keypoints[j][k][0] is not None:\n",
    "          relative_keypoints[j][k][0] -= frame_centers[j][0]\n",
    "      if relative_keypoints[j][k][1] is not None:\n",
    "        relative_keypoints[j][k][1] -= frame_centers[j][1]\n",
    "\n",
    "  frame=0\n",
    "  for i in range(len(relative_keypoints)):   #each frame\n",
    "    countx=0\n",
    "    county=0\n",
    "    for j in range(len(relative_keypoints[i])):   #34 keypoints\n",
    "      if relative_keypoints[i][j][0] is None:\n",
    "        countx+=1\n",
    "      if relative_keypoints[i][j][1] is None:\n",
    "        county+=1\n",
    "    if(countx== 34 and county==34):\n",
    "#       print(\"empty\")\n",
    "      return []\n",
    "\n",
    "    for j in range(len(relative_keypoints[i])):   #34 keypoints\n",
    "      if relative_keypoints[i][j][0] is None:\n",
    "#         print(\"frame : \",i)\n",
    "        # ReplacebyAverage(j,relative_keypoints[i])\n",
    "        relative_keypoints[i][j][0] = -1\n",
    "      if relative_keypoints[i][j][1] is None:\n",
    "        # ReplacebyAverage(j,relative_keypoints[i])\n",
    "        relative_keypoints[i][j][1] = -1\n",
    "  return relative_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84b5d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfKeypoints=34\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# calculate the center of the object in each frame\n",
    "\n",
    "def CentralisedKeypoints2(keypoints,live = False):\n",
    "  frame_centers = []\n",
    "  for frame_keypoints in keypoints:\n",
    "    # assume the center is the mean of all keypoints\n",
    "    center_x = np.nanmean([kp[0] for kp in frame_keypoints if kp[0] is not None])\n",
    "    center_y = np.nanmean([kp[1] for kp in frame_keypoints if kp[1] is not None])\n",
    "    frame_centers.append((center_x, center_y))\n",
    "\n",
    "\n",
    "  relative_keypoints = keypoints\n",
    "\n",
    "  for j in range(len(relative_keypoints)):               #frame no j\n",
    "    for k in range(len(relative_keypoints[j])):           # k keypoint of frame j\n",
    "      if relative_keypoints[j][k][0] is not None:\n",
    "          relative_keypoints[j][k][0] -= frame_centers[j][0]\n",
    "      if relative_keypoints[j][k][1] is not None:\n",
    "        relative_keypoints[j][k][1] -= frame_centers[j][1]\n",
    "\n",
    "    frames_keypoints=[]\n",
    "    for j in range(len(relative_keypoints)):\n",
    "        flag=1\n",
    "        for k in range(len(relative_keypoints[j])):\n",
    "          if relative_keypoints[j][k][0] is None or relative_keypoints[j][k][1] is None:\n",
    "            flag=0\n",
    "            break\n",
    "        if(flag==1):\n",
    "          frames_keypoints.append(relative_keypoints[j])\n",
    "\n",
    "    if(len(frames_keypoints)>0):\n",
    "      kk = [[0.0,0.0] for _ in range(numOfKeypoints)]\n",
    "      for x in range (16-len(frames_keypoints)):\n",
    "            frames_keypoints.append(kk)\n",
    "      return frames_keypoints\n",
    "\n",
    "  if live:\n",
    "        return []\n",
    "  return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb037a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfKeypoints = 35\n",
    "def getKeyPointsforFrame(frame):\n",
    "  img,results = mpPoseImg(frame)\n",
    "  keypoints = [[None,None] for _ in range(numOfKeypoints)]\n",
    "  if results.pose_landmarks == None:\n",
    "    return keypoints\n",
    "    \n",
    "  landmarks = results.pose_landmarks\n",
    "  for i in range(numOfKeypoints-2):\n",
    "     mark = landmarks.landmark[i]\n",
    "     keypoints[i][0]=mark.x\n",
    "     keypoints[i][1]=mark.y\n",
    "  #------------------------------------------------------------------------------------------------\n",
    "  try:\n",
    "    # MID HIP COORDINATES\n",
    "      left_hip_index = 23\n",
    "      right_hip_index = 24\n",
    "      Mid_hip_x =  (keypoints[left_hip_index][0]+keypoints[right_hip_index][0])/2\n",
    "      Mid_hip_y =(keypoints[left_hip_index][1]+keypoints[right_hip_index][1])/2\n",
    "      # keypoints.append([Mid_hip_x,Mid_hip_y])\n",
    "      keypoints[33][0]=Mid_hip_x\n",
    "      keypoints[33][1]=Mid_hip_y\n",
    "                          \n",
    "  except:\n",
    "      pass\n",
    "      \n",
    "  #------------------------------------------------------------------------------------------------\n",
    "  try:\n",
    "    # NECK COORDINATES\n",
    "      left_shoulder_index = 11\n",
    "      right_shoulder_index = 12\n",
    "      Neck_x =  (keypoints[left_shoulder_index][0]+keypoints[right_shoulder_index][0])/2\n",
    "      Neck_y =(keypoints[left_shoulder_index][1]+keypoints[right_shoulder_index][1])/2\n",
    "      # keypoints.append([Neck_x,Neck_y])\n",
    "      keypoints[34][0]=Neck_x\n",
    "      keypoints[34][1]=Neck_y\n",
    "                          \n",
    "  except:\n",
    "      pass\n",
    "\n",
    "  #------------------------------------------------------------------------------------------------\n",
    "     \n",
    "  return keypoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a83fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "RGBmodel = models.load_model('RGBStream.h5')\n",
    "Posemodel = models.load_model('PoseStream2.h5')\n",
    "\n",
    "labels=['Adhomukhasvanasana',\n",
    "  'Ardhachakrasana',\n",
    "  'Bhujangasana',\n",
    "  'Dhanurasana',\n",
    "  'Marjariasana',\n",
    "  'Padahastasana',\n",
    "  'Padmasana',\n",
    "  'Pawanmuktasana',\n",
    "  'Phalakasana',\n",
    "  'Sarvangasana',\n",
    "  'Sashankasana',\n",
    "  'Setubandhasana',\n",
    "  'Shavasana',\n",
    "  'Tadasana',\n",
    "  'Trikonasana',\n",
    "  'Ustrasana',\n",
    "  'Vakrasana',\n",
    "  'Virbhadrasana1',\n",
    "  'Virbhadrasana2',\n",
    "  'Vrikshasana']\n",
    "  \n",
    "\n",
    "def predictYogaPose(video,keypoints,integer = False,RGBRatio = 0.3, PoseRatio = 0.7):\n",
    "  softmaxRGB = RGBmodel.predict(video)\n",
    "  softmaxPose = Posemodel.predict(keypoints)\n",
    "  combined_softmax = (softmaxPose[0]*RGBRatio + softmaxPose[0]*PoseRatio) \n",
    "  \n",
    "  predicted_labels = np.argmax(combined_softmax)\n",
    "  \n",
    "  if(integer == True):\n",
    "    return predicted_labels\n",
    "#   print(combined_softmax)\n",
    "#   print(max(combined_softmax))\n",
    "  if max(combined_softmax) < 0.95:\n",
    "    return \"\"\n",
    "  return labels[predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e12e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
