{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhushiBhambri/YogNet/blob/main/PoseStreamModel/FinalPoseStream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYumV5IZ2mp-"
      },
      "outputs": [],
      "source": [
        "# RGBmodel = load_model('RGBStream.h5')\n",
        "# Posemodel = load_model('PoseStream.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Major_Project_Cse')\n",
        "\n",
        "%cd \"/content/drive/MyDrive/Major_Project_Cse\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-BOp1DJ1NhE",
        "outputId": "f269305a-619a-444a-b566-c7ebcd7dbeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Major_Project_Cse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Setup the Pose function for images - independently for the images standalone processing.\n",
        "pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.8,model_complexity=2)\n",
        "\n",
        "# Setup the Pose function for videos - for video processing.\n",
        "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7,\n",
        "                          min_tracking_confidence=0.7)\n",
        "\n",
        "# Initialize mediapipe drawing class - to draw the landmarks points.\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "def mpPoseImg(image_pose, pose=pose_image, draw=False, display=False):\n",
        "    \n",
        "    annotated_image = image_pose.copy()\n",
        "    \n",
        "    image_in_RGB = cv2.cvtColor(image_pose, cv2.COLOR_BGR2RGB)\n",
        " \n",
        "    \n",
        "    results = pose.process(image_in_RGB)\n",
        "\n",
        "    if results.pose_landmarks and draw:    \n",
        "      mp_drawing.draw_landmarks(image=annotated_image,landmark_list=results.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n",
        "                                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "\n",
        "\n",
        "        # mp_drawing.draw_landmarks(image=original_image, landmark_list=resultant.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n",
        "        #                           landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),thickness=3, circle_radius=3),\n",
        "        #                           connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),thickness=2, circle_radius=2))\n",
        "\n",
        "    if display:\n",
        "            \n",
        "            # plt.figure(figsize=[22,22])\n",
        "            # plt.subplot(121);plt.imshow(image_pose[:,:,::-1]);plt.title(\"Input Image\");plt.axis('off');\n",
        "            # plt.subplot(122);plt.imshow(annotated_image[:,:,::-1]);plt.title(\"Pose detected Image\");plt.axis('off');\n",
        "            cv2.imshow(annotated_image)\n",
        "            return results\n",
        "\n",
        "    else:\n",
        "        return annotated_image,results\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahy_CKjVkXO5",
        "outputId": "856aa202-3c64-478e-9eb8-31870813d509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.2.1\n",
            "Downloading model to /usr/local/lib/python3.9/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the center of the object in each frame\n",
        "def CentralisedKeypoints1(keypoints):\n",
        "  frame_centers = []\n",
        " \n",
        "  for frame_keypoints in keypoints:\n",
        "    # assume the center is the mean of all keypoints\n",
        "    center_x = np.nanmean([kp[0] for kp in frame_keypoints if kp[0] is not None])\n",
        "    center_y = np.nanmean([kp[1] for kp in frame_keypoints if kp[1] is not None])\n",
        "    frame_centers.append((center_x, center_y))\n",
        "\n",
        "  relative_keypoints = keypoints\n",
        "\n",
        "  for j in range(len(relative_keypoints)):               #frame no\n",
        "    for k in range(len(relative_keypoints[j])):          # each keypoint of frame\n",
        "      if relative_keypoints[j][k][0] is not None:\n",
        "          relative_keypoints[j][k][0] -= frame_centers[j][0]\n",
        "      if relative_keypoints[j][k][1] is not None:\n",
        "        relative_keypoints[j][k][1] -= frame_centers[j][1]\n",
        "\n",
        "  frame=0\n",
        "  for i in range(len(relative_keypoints)):   #each frame\n",
        "    countx=0\n",
        "    county=0\n",
        "    for j in range(len(relative_keypoints[i])):   #34 keypoints\n",
        "      if relative_keypoints[i][j][0] is None:\n",
        "        relative_keypoints[i][j][0] = -1\n",
        "        countx+=1\n",
        "      if relative_keypoints[i][j][1] is None:\n",
        "        relative_keypoints[i][j][1] = -1\n",
        "        county+=1\n",
        "    if(countx== 34 and county==34):\n",
        "       frame+=1\n",
        "  if(frame>0): \n",
        "    return None\n",
        "  return relative_keypoints\n",
        "\n"
      ],
      "metadata": {
        "id": "9UIv3_tewvLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfKeypoints=34\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# calculate the center of the object in each frame\n",
        "\n",
        "def CentralisedKeypoints2(keypoints):\n",
        "  frame_centers = []\n",
        "  for frame_keypoints in keypoints:\n",
        "    # assume the center is the mean of all keypoints\n",
        "    center_x = np.nanmean([kp[0] for kp in frame_keypoints if kp[0] is not None])\n",
        "    center_y = np.nanmean([kp[1] for kp in frame_keypoints if kp[1] is not None])\n",
        "    frame_centers.append((center_x, center_y))\n",
        "\n",
        "\n",
        "  relative_keypoints = keypoints\n",
        "\n",
        "  for j in range(len(relative_keypoints)):               #frame no j\n",
        "    for k in range(len(relative_keypoints[j])):          # k keypoint of frame j\n",
        "      if relative_keypoints[j][k][0] is not None:\n",
        "          relative_keypoints[j][k][0] -= frame_centers[j][0]\n",
        "      if relative_keypoints[j][k][1] is not None:\n",
        "        relative_keypoints[j][k][1] -= frame_centers[j][1]\n",
        "\n",
        "    frames_keypoints=[]\n",
        "    for j in range(len(relative_keypoints)):\n",
        "        flag=1\n",
        "        for k in range(len(relative_keypoints[j])):\n",
        "          if relative_keypoints[j][k][0] is None or relative_keypoints[j][k][1] is None:\n",
        "            flag=0\n",
        "            break\n",
        "        if(flag==1):\n",
        "          frames_keypoints.append(relative_keypoints[j])\n",
        "\n",
        "    if(len(frames_keypoints)>0):\n",
        "      kk = [[0.0,0.0] for _ in range(numOfKeypoints)]\n",
        "      for x in range (16-len(frames_keypoints)):\n",
        "            frames_keypoints.append(kk)\n",
        "      return frames_keypoints\n",
        "\n",
        "  return None\n",
        "\n"
      ],
      "metadata": {
        "id": "9xjtGTMxp0Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfKeypoints = 34\n",
        "def getKeyPointsforFrame(frame):\n",
        "  img,results = mpPoseImg(frame)\n",
        "  keypoints = [[None,None] for _ in range(numOfKeypoints)]\n",
        "  if results.pose_landmarks == None:\n",
        "    return keypoints\n",
        "    \n",
        "  landmarks = results.pose_landmarks\n",
        "  for i in range(numOfKeypoints-2):\n",
        "     mark = landmarks.landmark[i]\n",
        "     keypoints[i][0]=mark.x\n",
        "     keypoints[i][1]=mark.y\n",
        "  #------------------------------------------------------------------------------------------------\n",
        "  try:\n",
        "    # MID HIP COORDINATES\n",
        "      left_hip_index = 23\n",
        "      right_hip_index = 24\n",
        "      Mid_hip_x =  (keypoints[left_hip_index][0]+keypoints[right_hip_index][0])/2\n",
        "      Mid_hip_y =(keypoints[left_hip_index][1]+keypoints[right_hip_index][1])/2\n",
        "      # keypoints.append([Mid_hip_x,Mid_hip_y])\n",
        "      keypoints[32][0]=Mid_hip_x\n",
        "      keypoints[32][1]=Mid_hip_y\n",
        "                          \n",
        "  except:\n",
        "      pass\n",
        "      \n",
        "  #------------------------------------------------------------------------------------------------\n",
        "  try:\n",
        "    # NECK COORDINATES\n",
        "      left_shoulder_index = 11\n",
        "      right_shoulder_index = 12\n",
        "      Neck_x =  (keypoints[left_shoulder_index][0]+keypoints[right_shoulder_index][0])/2\n",
        "      Neck_y =(keypoints[left_shoulder_index][1]+keypoints[right_shoulder_index][1])/2\n",
        "      # keypoints.append([Neck_x,Neck_y])\n",
        "      keypoints[33][0]=Neck_x\n",
        "      keypoints[33][1]=Neck_y\n",
        "                          \n",
        "  except:\n",
        "      pass\n",
        "\n",
        "  #------------------------------------------------------------------------------------------------\n",
        "     \n",
        "  return keypoints"
      ],
      "metadata": {
        "id": "BE_aOtojxwjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import initializers\n",
        "from keras.layers import Conv3D, MaxPooling3D,Dense,ZeroPadding3D,Flatten,Activation,BatchNormalization,RandomFlip,RandomRotation,Rescaling\n",
        "from keras.models import load_model\n",
        "\n"
      ],
      "metadata": {
        "id": "g8A6vXa45cwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the data from the CSV file\n",
        "data = pd.read_csv('train_data.csv')\n",
        "\n",
        "# load the keypoints and labels into separate variables\n",
        "# train_keypoints = list(data['keypoints'])\n",
        "train_keypoints=[]\n",
        "train_labels = list(data['label'])\n",
        "\n",
        "numOfKeypoints = 34\n",
        "import ast\n",
        "for keypoints_str in data['keypoints']:\n",
        "    keypoints_list = ast.literal_eval(keypoints_str)\n",
        "    train_keypoints.append(keypoints_list)"
      ],
      "metadata": {
        "id": "DCztxQAU14_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_keypoints = []\n",
        "new_train_labels = []\n",
        "for i in range(len(train_keypoints)):\n",
        "  keypoints = CentralisedKeypoints1(train_keypoints[i])\n",
        "  if(keypoints is not None):\n",
        "     new_train_keypoints.append(keypoints)\n",
        "     new_train_labels.append(train_labels[i])\n"
      ],
      "metadata": {
        "id": "7lxtUff-2Ev_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_train_keypoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeIF_s8_2Xzw",
        "outputId": "ead67c5e-9815-4662-8be9-7971b809618a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "916"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_videos = np.asarray(train_videos)\n",
        "train_keypoints = np.asarray(train_keypoints)\n",
        "train_labels = np.asarray(train_labels).astype('int32')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "XKey_train,XKey_test,yKey_train,yKey_test = train_test_split(train_keypoints,train_labels,test_size=0.25,shuffle=True)"
      ],
      "metadata": {
        "id": "n9NQTKVJ6pd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XKey_train = tf.convert_to_tensor(XKey_train, dtype=tf.float32)\n",
        "yKey_train = tf.convert_to_tensor(yKey_train, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "ISAy0WtZ2vyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models, layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, Dense, Dropout, TimeDistributed, GlobalAveragePooling1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import GlorotNormal\n",
        "from keras.regularizers import L1L2\n",
        "\n",
        "yKey_train = np.squeeze(yKey_train)\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "# Define model input shape\n",
        "input_shape = (16, 34, 2)\n",
        "\n",
        "# Build model architecture\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu'),input_shape = input_shape))\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Conv1D(filters=128, kernel_size=3, activation='relu')))\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "model.add(TimeDistributed(Conv1D(filters=50, kernel_size=3, activation='relu')))\n",
        "# model.add(TimeDistributed(BatchNormalization()))\n",
        "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "\n",
        "# flatten output from CNN layers\n",
        "model.add(TimeDistributed(GlobalAveragePooling1D()))\n",
        "\n",
        "# add LSTM layer\n",
        "# model.add(LSTM(100, dropout=0.0, recurrent_dropout=0.0, kernel_initializer=GlorotNormal(seed=42), recurrent_regularizer=L1L2(l1=0.0, l2=0.001), bias_regularizer=L1L2(l1=0.0, l2=0.001), recurrent_initializer=GlorotNormal(seed=42), return_sequences=False))\n",
        "model.add(LSTM(100, recurrent_regularizer=L1L2(l1=0.01, l2=0.001), bias_regularizer=L1L2(l1=0.01, l2=0.001), recurrent_initializer=GlorotNormal(seed=42), return_sequences=False))\n",
        "\n",
        "# TODO: forget bias \n",
        "# TODO: L1 = 0.01\n",
        "\n",
        "\n",
        "# add fully connected layers\n",
        "\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(100, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(80, activation='relu'))\n",
        "\n",
        "# add Softmax layer\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "adam = Adam(learning_rate=0.001) \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "# print(model.summary())\n",
        "\n",
        "history = model.fit(XKey_train,yKey_train,batch_size=32,epochs = 300,validation_split = 0.2)"
      ],
      "metadata": {
        "id": "dW4Fb2a3zUB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d61f6a-6c36-46b4-8c5e-0b7f6919d09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "23/23 [==============================] - 2s 102ms/step - loss: 21.1246 - accuracy: 0.0977 - val_loss: 17.1037 - val_accuracy: 0.1484\n",
            "Epoch 2/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 14.1230 - accuracy: 0.1664 - val_loss: 11.1578 - val_accuracy: 0.0549\n",
            "Epoch 3/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 8.9906 - accuracy: 0.1829 - val_loss: 7.0700 - val_accuracy: 0.2308\n",
            "Epoch 4/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 5.8047 - accuracy: 0.2600 - val_loss: 4.7437 - val_accuracy: 0.2143\n",
            "Epoch 5/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 4.0726 - accuracy: 0.2627 - val_loss: 3.4800 - val_accuracy: 0.3297\n",
            "Epoch 6/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 3.1694 - accuracy: 0.3453 - val_loss: 2.9011 - val_accuracy: 0.3626\n",
            "Epoch 7/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 2.8978 - accuracy: 0.3796 - val_loss: 2.7390 - val_accuracy: 0.4176\n",
            "Epoch 8/300\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 2.7398 - accuracy: 0.4058 - val_loss: 2.6140 - val_accuracy: 0.3956\n",
            "Epoch 9/300\n",
            "23/23 [==============================] - 2s 107ms/step - loss: 2.6148 - accuracy: 0.4264 - val_loss: 2.5152 - val_accuracy: 0.4286\n",
            "Epoch 10/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 2.5042 - accuracy: 0.4594 - val_loss: 2.4256 - val_accuracy: 0.5165\n",
            "Epoch 11/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 2.4211 - accuracy: 0.4677 - val_loss: 2.4218 - val_accuracy: 0.4286\n",
            "Epoch 12/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 2.4203 - accuracy: 0.4649 - val_loss: 2.3355 - val_accuracy: 0.4670\n",
            "Epoch 13/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 2.3170 - accuracy: 0.5076 - val_loss: 2.2394 - val_accuracy: 0.4945\n",
            "Epoch 14/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 2.3819 - accuracy: 0.4732 - val_loss: 2.2420 - val_accuracy: 0.5165\n",
            "Epoch 15/300\n",
            "23/23 [==============================] - 2s 100ms/step - loss: 2.2669 - accuracy: 0.4979 - val_loss: 2.1649 - val_accuracy: 0.4945\n",
            "Epoch 16/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 2.1699 - accuracy: 0.5337 - val_loss: 2.0876 - val_accuracy: 0.5495\n",
            "Epoch 17/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 2.1049 - accuracy: 0.5488 - val_loss: 2.0716 - val_accuracy: 0.6099\n",
            "Epoch 18/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 2.0712 - accuracy: 0.5158 - val_loss: 1.9669 - val_accuracy: 0.5879\n",
            "Epoch 19/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 2.0206 - accuracy: 0.5708 - val_loss: 1.9801 - val_accuracy: 0.5659\n",
            "Epoch 20/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.9795 - accuracy: 0.5626 - val_loss: 1.9442 - val_accuracy: 0.5769\n",
            "Epoch 21/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.9378 - accuracy: 0.5860 - val_loss: 1.8826 - val_accuracy: 0.6044\n",
            "Epoch 22/300\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 1.8984 - accuracy: 0.5777 - val_loss: 1.8225 - val_accuracy: 0.6099\n",
            "Epoch 23/300\n",
            "23/23 [==============================] - 3s 123ms/step - loss: 1.8132 - accuracy: 0.6080 - val_loss: 1.7910 - val_accuracy: 0.6319\n",
            "Epoch 24/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.7947 - accuracy: 0.6149 - val_loss: 1.7994 - val_accuracy: 0.5495\n",
            "Epoch 25/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 1.7660 - accuracy: 0.5997 - val_loss: 1.7078 - val_accuracy: 0.6044\n",
            "Epoch 26/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 1.7090 - accuracy: 0.6107 - val_loss: 1.6661 - val_accuracy: 0.6374\n",
            "Epoch 27/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 1.7007 - accuracy: 0.6080 - val_loss: 1.7019 - val_accuracy: 0.5769\n",
            "Epoch 28/300\n",
            "23/23 [==============================] - 3s 132ms/step - loss: 1.6397 - accuracy: 0.6149 - val_loss: 1.5646 - val_accuracy: 0.6154\n",
            "Epoch 29/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 1.6333 - accuracy: 0.6217 - val_loss: 1.6332 - val_accuracy: 0.6264\n",
            "Epoch 30/300\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 1.5951 - accuracy: 0.6355 - val_loss: 1.6152 - val_accuracy: 0.5824\n",
            "Epoch 31/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 1.5651 - accuracy: 0.6300 - val_loss: 1.5450 - val_accuracy: 0.6209\n",
            "Epoch 32/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.5284 - accuracy: 0.6121 - val_loss: 1.5148 - val_accuracy: 0.6264\n",
            "Epoch 33/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 1.4805 - accuracy: 0.6506 - val_loss: 1.4254 - val_accuracy: 0.6648\n",
            "Epoch 34/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 1.4157 - accuracy: 0.6602 - val_loss: 1.3801 - val_accuracy: 0.6868\n",
            "Epoch 35/300\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 1.3860 - accuracy: 0.6492 - val_loss: 1.3971 - val_accuracy: 0.6429\n",
            "Epoch 36/300\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 1.3505 - accuracy: 0.6644 - val_loss: 1.3565 - val_accuracy: 0.6703\n",
            "Epoch 37/300\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 1.4030 - accuracy: 0.6382 - val_loss: 1.3460 - val_accuracy: 0.6484\n",
            "Epoch 38/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 1.3455 - accuracy: 0.6575 - val_loss: 1.3355 - val_accuracy: 0.6154\n",
            "Epoch 39/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.2596 - accuracy: 0.6781 - val_loss: 1.2611 - val_accuracy: 0.7033\n",
            "Epoch 40/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.3239 - accuracy: 0.6341 - val_loss: 1.3663 - val_accuracy: 0.6429\n",
            "Epoch 41/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.2703 - accuracy: 0.6547 - val_loss: 1.2155 - val_accuracy: 0.6758\n",
            "Epoch 42/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 1.1364 - accuracy: 0.6988 - val_loss: 1.1606 - val_accuracy: 0.7088\n",
            "Epoch 43/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 1.1399 - accuracy: 0.6768 - val_loss: 1.1467 - val_accuracy: 0.6374\n",
            "Epoch 44/300\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 1.1419 - accuracy: 0.6850 - val_loss: 1.1034 - val_accuracy: 0.7253\n",
            "Epoch 45/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 1.0722 - accuracy: 0.7084 - val_loss: 1.0797 - val_accuracy: 0.7143\n",
            "Epoch 46/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.0648 - accuracy: 0.6891 - val_loss: 1.0584 - val_accuracy: 0.6978\n",
            "Epoch 47/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.0278 - accuracy: 0.7015 - val_loss: 1.0734 - val_accuracy: 0.7088\n",
            "Epoch 48/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 1.0163 - accuracy: 0.6836 - val_loss: 1.1036 - val_accuracy: 0.6758\n",
            "Epoch 49/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 1.0813 - accuracy: 0.6850 - val_loss: 1.1681 - val_accuracy: 0.6648\n",
            "Epoch 50/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 1.0148 - accuracy: 0.6974 - val_loss: 1.1164 - val_accuracy: 0.6703\n",
            "Epoch 51/300\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 0.9877 - accuracy: 0.7098 - val_loss: 1.0941 - val_accuracy: 0.6648\n",
            "Epoch 52/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.0462 - accuracy: 0.6974 - val_loss: 1.1459 - val_accuracy: 0.6758\n",
            "Epoch 53/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 1.0572 - accuracy: 0.6878 - val_loss: 1.0958 - val_accuracy: 0.7033\n",
            "Epoch 54/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 1.0056 - accuracy: 0.6919 - val_loss: 1.0501 - val_accuracy: 0.7143\n",
            "Epoch 55/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.9546 - accuracy: 0.7125 - val_loss: 1.0609 - val_accuracy: 0.7198\n",
            "Epoch 56/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.9489 - accuracy: 0.7084 - val_loss: 1.0083 - val_accuracy: 0.7473\n",
            "Epoch 57/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.9812 - accuracy: 0.7056 - val_loss: 1.0545 - val_accuracy: 0.7143\n",
            "Epoch 58/300\n",
            "23/23 [==============================] - 2s 100ms/step - loss: 0.9453 - accuracy: 0.7070 - val_loss: 1.0830 - val_accuracy: 0.7143\n",
            "Epoch 59/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.9295 - accuracy: 0.7180 - val_loss: 1.0198 - val_accuracy: 0.7363\n",
            "Epoch 60/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.9858 - accuracy: 0.7111 - val_loss: 1.1636 - val_accuracy: 0.6648\n",
            "Epoch 61/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.9870 - accuracy: 0.6974 - val_loss: 1.0629 - val_accuracy: 0.7143\n",
            "Epoch 62/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 1.0333 - accuracy: 0.6768 - val_loss: 1.2192 - val_accuracy: 0.6648\n",
            "Epoch 63/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 1.0445 - accuracy: 0.6919 - val_loss: 1.0697 - val_accuracy: 0.7143\n",
            "Epoch 64/300\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.9687 - accuracy: 0.7098 - val_loss: 1.0608 - val_accuracy: 0.7033\n",
            "Epoch 65/300\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 0.9601 - accuracy: 0.7084 - val_loss: 1.0805 - val_accuracy: 0.7198\n",
            "Epoch 66/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.9180 - accuracy: 0.7194 - val_loss: 1.0417 - val_accuracy: 0.7253\n",
            "Epoch 67/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.9093 - accuracy: 0.7331 - val_loss: 1.0589 - val_accuracy: 0.7198\n",
            "Epoch 68/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.9391 - accuracy: 0.7318 - val_loss: 1.0526 - val_accuracy: 0.7088\n",
            "Epoch 69/300\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.9250 - accuracy: 0.7166 - val_loss: 1.0858 - val_accuracy: 0.6923\n",
            "Epoch 70/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8824 - accuracy: 0.7290 - val_loss: 1.1802 - val_accuracy: 0.6538\n",
            "Epoch 71/300\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 0.9150 - accuracy: 0.7111 - val_loss: 1.0614 - val_accuracy: 0.6923\n",
            "Epoch 72/300\n",
            "23/23 [==============================] - 2s 102ms/step - loss: 0.8950 - accuracy: 0.7318 - val_loss: 1.0819 - val_accuracy: 0.7473\n",
            "Epoch 73/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.9156 - accuracy: 0.7373 - val_loss: 1.0754 - val_accuracy: 0.7033\n",
            "Epoch 74/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.9460 - accuracy: 0.7098 - val_loss: 1.0654 - val_accuracy: 0.7088\n",
            "Epoch 75/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.9071 - accuracy: 0.7221 - val_loss: 1.0397 - val_accuracy: 0.7198\n",
            "Epoch 76/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8806 - accuracy: 0.7552 - val_loss: 1.0147 - val_accuracy: 0.7253\n",
            "Epoch 77/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.8552 - accuracy: 0.7510 - val_loss: 1.0243 - val_accuracy: 0.7198\n",
            "Epoch 78/300\n",
            "23/23 [==============================] - 2s 102ms/step - loss: 0.8307 - accuracy: 0.7373 - val_loss: 1.1052 - val_accuracy: 0.6758\n",
            "Epoch 79/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.8816 - accuracy: 0.7194 - val_loss: 1.0428 - val_accuracy: 0.7198\n",
            "Epoch 80/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.9223 - accuracy: 0.7015 - val_loss: 1.0698 - val_accuracy: 0.7198\n",
            "Epoch 81/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.9112 - accuracy: 0.7483 - val_loss: 1.0530 - val_accuracy: 0.7253\n",
            "Epoch 82/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.9047 - accuracy: 0.7331 - val_loss: 0.9996 - val_accuracy: 0.7363\n",
            "Epoch 83/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.8527 - accuracy: 0.7538 - val_loss: 1.0341 - val_accuracy: 0.7308\n",
            "Epoch 84/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8500 - accuracy: 0.7373 - val_loss: 1.1452 - val_accuracy: 0.6978\n",
            "Epoch 85/300\n",
            "23/23 [==============================] - 2s 101ms/step - loss: 0.8688 - accuracy: 0.7276 - val_loss: 1.0279 - val_accuracy: 0.6758\n",
            "Epoch 86/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 0.8457 - accuracy: 0.7400 - val_loss: 1.0344 - val_accuracy: 0.7253\n",
            "Epoch 87/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8343 - accuracy: 0.7717 - val_loss: 0.9987 - val_accuracy: 0.7253\n",
            "Epoch 88/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.7985 - accuracy: 0.7607 - val_loss: 0.9810 - val_accuracy: 0.7308\n",
            "Epoch 89/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8138 - accuracy: 0.7552 - val_loss: 1.0535 - val_accuracy: 0.7033\n",
            "Epoch 90/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.8673 - accuracy: 0.7455 - val_loss: 1.0375 - val_accuracy: 0.7253\n",
            "Epoch 91/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8061 - accuracy: 0.7620 - val_loss: 1.0567 - val_accuracy: 0.7198\n",
            "Epoch 92/300\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 0.8448 - accuracy: 0.7538 - val_loss: 1.0537 - val_accuracy: 0.7253\n",
            "Epoch 93/300\n",
            "23/23 [==============================] - 3s 121ms/step - loss: 0.8729 - accuracy: 0.7469 - val_loss: 1.1065 - val_accuracy: 0.6868\n",
            "Epoch 94/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8460 - accuracy: 0.7593 - val_loss: 1.0036 - val_accuracy: 0.7308\n",
            "Epoch 95/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8515 - accuracy: 0.7442 - val_loss: 1.0494 - val_accuracy: 0.7033\n",
            "Epoch 96/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8372 - accuracy: 0.7497 - val_loss: 1.1057 - val_accuracy: 0.6813\n",
            "Epoch 97/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.8234 - accuracy: 0.7662 - val_loss: 1.0947 - val_accuracy: 0.7198\n",
            "Epoch 98/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.7829 - accuracy: 0.7455 - val_loss: 1.0316 - val_accuracy: 0.7308\n",
            "Epoch 99/300\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 0.7735 - accuracy: 0.7717 - val_loss: 1.0340 - val_accuracy: 0.7363\n",
            "Epoch 100/300\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.7754 - accuracy: 0.7634 - val_loss: 1.0566 - val_accuracy: 0.7253\n",
            "Epoch 101/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.7946 - accuracy: 0.7648 - val_loss: 1.0440 - val_accuracy: 0.7308\n",
            "Epoch 102/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.7726 - accuracy: 0.7538 - val_loss: 1.0336 - val_accuracy: 0.7363\n",
            "Epoch 103/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.8454 - accuracy: 0.7565 - val_loss: 1.1742 - val_accuracy: 0.6593\n",
            "Epoch 104/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.8661 - accuracy: 0.7510 - val_loss: 1.0332 - val_accuracy: 0.7308\n",
            "Epoch 105/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.8472 - accuracy: 0.7552 - val_loss: 1.0250 - val_accuracy: 0.7473\n",
            "Epoch 106/300\n",
            "23/23 [==============================] - 2s 99ms/step - loss: 0.7616 - accuracy: 0.7840 - val_loss: 1.0359 - val_accuracy: 0.7143\n",
            "Epoch 107/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.7336 - accuracy: 0.7827 - val_loss: 1.0539 - val_accuracy: 0.7308\n",
            "Epoch 108/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.7270 - accuracy: 0.7799 - val_loss: 1.0388 - val_accuracy: 0.7418\n",
            "Epoch 109/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7747 - accuracy: 0.7662 - val_loss: 0.9875 - val_accuracy: 0.7143\n",
            "Epoch 110/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7970 - accuracy: 0.7730 - val_loss: 1.0245 - val_accuracy: 0.7363\n",
            "Epoch 111/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.7805 - accuracy: 0.7758 - val_loss: 1.0294 - val_accuracy: 0.7253\n",
            "Epoch 112/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.7635 - accuracy: 0.7758 - val_loss: 1.0287 - val_accuracy: 0.7418\n",
            "Epoch 113/300\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 0.7508 - accuracy: 0.7634 - val_loss: 1.0655 - val_accuracy: 0.7088\n",
            "Epoch 114/300\n",
            "23/23 [==============================] - 2s 109ms/step - loss: 0.7202 - accuracy: 0.7964 - val_loss: 0.9567 - val_accuracy: 0.7473\n",
            "Epoch 115/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7208 - accuracy: 0.7854 - val_loss: 1.2469 - val_accuracy: 0.6703\n",
            "Epoch 116/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8022 - accuracy: 0.7634 - val_loss: 1.0964 - val_accuracy: 0.6648\n",
            "Epoch 117/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7640 - accuracy: 0.7620 - val_loss: 1.0685 - val_accuracy: 0.7143\n",
            "Epoch 118/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.7074 - accuracy: 0.8074 - val_loss: 1.0691 - val_accuracy: 0.7308\n",
            "Epoch 119/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.7355 - accuracy: 0.7813 - val_loss: 0.9879 - val_accuracy: 0.7308\n",
            "Epoch 120/300\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 0.7742 - accuracy: 0.7607 - val_loss: 1.1776 - val_accuracy: 0.6868\n",
            "Epoch 121/300\n",
            "23/23 [==============================] - 3s 120ms/step - loss: 0.7846 - accuracy: 0.7772 - val_loss: 1.0542 - val_accuracy: 0.7253\n",
            "Epoch 122/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.8008 - accuracy: 0.7895 - val_loss: 1.0765 - val_accuracy: 0.7308\n",
            "Epoch 123/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.7571 - accuracy: 0.7744 - val_loss: 1.1088 - val_accuracy: 0.7198\n",
            "Epoch 124/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.7538 - accuracy: 0.7785 - val_loss: 1.0347 - val_accuracy: 0.7473\n",
            "Epoch 125/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.7226 - accuracy: 0.7827 - val_loss: 1.0634 - val_accuracy: 0.7363\n",
            "Epoch 126/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.7192 - accuracy: 0.7937 - val_loss: 1.0259 - val_accuracy: 0.7308\n",
            "Epoch 127/300\n",
            "23/23 [==============================] - 2s 100ms/step - loss: 0.7295 - accuracy: 0.7758 - val_loss: 1.0096 - val_accuracy: 0.7253\n",
            "Epoch 128/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 0.7645 - accuracy: 0.7758 - val_loss: 1.0551 - val_accuracy: 0.7473\n",
            "Epoch 129/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.7054 - accuracy: 0.7964 - val_loss: 1.0079 - val_accuracy: 0.7418\n",
            "Epoch 130/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6839 - accuracy: 0.7895 - val_loss: 1.0750 - val_accuracy: 0.7363\n",
            "Epoch 131/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.7207 - accuracy: 0.7785 - val_loss: 1.0620 - val_accuracy: 0.7473\n",
            "Epoch 132/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.7385 - accuracy: 0.7813 - val_loss: 1.0187 - val_accuracy: 0.7418\n",
            "Epoch 133/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.6947 - accuracy: 0.8047 - val_loss: 1.0291 - val_accuracy: 0.7253\n",
            "Epoch 134/300\n",
            "23/23 [==============================] - 2s 101ms/step - loss: 0.7427 - accuracy: 0.7675 - val_loss: 1.0607 - val_accuracy: 0.7473\n",
            "Epoch 135/300\n",
            "23/23 [==============================] - 2s 107ms/step - loss: 0.7732 - accuracy: 0.7758 - val_loss: 1.0892 - val_accuracy: 0.6978\n",
            "Epoch 136/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.7176 - accuracy: 0.7895 - val_loss: 1.0092 - val_accuracy: 0.7308\n",
            "Epoch 137/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.7018 - accuracy: 0.7854 - val_loss: 1.0399 - val_accuracy: 0.7473\n",
            "Epoch 138/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.7111 - accuracy: 0.7895 - val_loss: 1.0429 - val_accuracy: 0.7308\n",
            "Epoch 139/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6854 - accuracy: 0.8074 - val_loss: 0.9694 - val_accuracy: 0.7473\n",
            "Epoch 140/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6804 - accuracy: 0.7992 - val_loss: 1.0870 - val_accuracy: 0.7363\n",
            "Epoch 141/300\n",
            "23/23 [==============================] - 2s 100ms/step - loss: 0.7692 - accuracy: 0.7730 - val_loss: 1.0672 - val_accuracy: 0.7473\n",
            "Epoch 142/300\n",
            "23/23 [==============================] - 2s 107ms/step - loss: 0.7043 - accuracy: 0.7950 - val_loss: 1.0300 - val_accuracy: 0.7473\n",
            "Epoch 143/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6806 - accuracy: 0.7937 - val_loss: 1.0753 - val_accuracy: 0.7418\n",
            "Epoch 144/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.7828 - accuracy: 0.7744 - val_loss: 1.0818 - val_accuracy: 0.7308\n",
            "Epoch 145/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.7503 - accuracy: 0.7813 - val_loss: 1.0633 - val_accuracy: 0.7582\n",
            "Epoch 146/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6782 - accuracy: 0.8019 - val_loss: 1.0319 - val_accuracy: 0.7637\n",
            "Epoch 147/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6617 - accuracy: 0.8074 - val_loss: 1.0580 - val_accuracy: 0.7582\n",
            "Epoch 148/300\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.6526 - accuracy: 0.8033 - val_loss: 1.0493 - val_accuracy: 0.7363\n",
            "Epoch 149/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 0.6711 - accuracy: 0.8006 - val_loss: 1.0572 - val_accuracy: 0.7527\n",
            "Epoch 150/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.6807 - accuracy: 0.8116 - val_loss: 1.1103 - val_accuracy: 0.7253\n",
            "Epoch 151/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.7514 - accuracy: 0.7840 - val_loss: 1.1176 - val_accuracy: 0.7363\n",
            "Epoch 152/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6897 - accuracy: 0.8047 - val_loss: 1.1105 - val_accuracy: 0.7198\n",
            "Epoch 153/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.6544 - accuracy: 0.7950 - val_loss: 1.0548 - val_accuracy: 0.7527\n",
            "Epoch 154/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6786 - accuracy: 0.7964 - val_loss: 1.0314 - val_accuracy: 0.7582\n",
            "Epoch 155/300\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.6804 - accuracy: 0.8116 - val_loss: 1.1147 - val_accuracy: 0.7363\n",
            "Epoch 156/300\n",
            "23/23 [==============================] - 2s 101ms/step - loss: 0.7423 - accuracy: 0.7730 - val_loss: 1.1235 - val_accuracy: 0.7473\n",
            "Epoch 157/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.7002 - accuracy: 0.7909 - val_loss: 1.1144 - val_accuracy: 0.7088\n",
            "Epoch 158/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6578 - accuracy: 0.8006 - val_loss: 1.0688 - val_accuracy: 0.7637\n",
            "Epoch 159/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6293 - accuracy: 0.8129 - val_loss: 1.0565 - val_accuracy: 0.7527\n",
            "Epoch 160/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.6509 - accuracy: 0.8102 - val_loss: 1.0388 - val_accuracy: 0.7692\n",
            "Epoch 161/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6547 - accuracy: 0.7992 - val_loss: 1.0628 - val_accuracy: 0.7582\n",
            "Epoch 162/300\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.6130 - accuracy: 0.8267 - val_loss: 1.0598 - val_accuracy: 0.7473\n",
            "Epoch 163/300\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.6270 - accuracy: 0.8116 - val_loss: 1.0702 - val_accuracy: 0.7253\n",
            "Epoch 164/300\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.6296 - accuracy: 0.8129 - val_loss: 1.0551 - val_accuracy: 0.7363\n",
            "Epoch 165/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6187 - accuracy: 0.8088 - val_loss: 1.0496 - val_accuracy: 0.7418\n",
            "Epoch 166/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6835 - accuracy: 0.8129 - val_loss: 1.1105 - val_accuracy: 0.7527\n",
            "Epoch 167/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6954 - accuracy: 0.8047 - val_loss: 1.0371 - val_accuracy: 0.7418\n",
            "Epoch 168/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.7475 - accuracy: 0.8019 - val_loss: 1.1942 - val_accuracy: 0.7308\n",
            "Epoch 169/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.7439 - accuracy: 0.8074 - val_loss: 1.0953 - val_accuracy: 0.7418\n",
            "Epoch 170/300\n",
            "23/23 [==============================] - 2s 106ms/step - loss: 0.6925 - accuracy: 0.8129 - val_loss: 1.2162 - val_accuracy: 0.6978\n",
            "Epoch 171/300\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 0.7168 - accuracy: 0.7950 - val_loss: 1.0276 - val_accuracy: 0.7747\n",
            "Epoch 172/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.6507 - accuracy: 0.8143 - val_loss: 1.0265 - val_accuracy: 0.7473\n",
            "Epoch 173/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6011 - accuracy: 0.8171 - val_loss: 1.0302 - val_accuracy: 0.7473\n",
            "Epoch 174/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.5822 - accuracy: 0.8391 - val_loss: 1.0635 - val_accuracy: 0.7637\n",
            "Epoch 175/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5713 - accuracy: 0.8239 - val_loss: 1.0494 - val_accuracy: 0.7582\n",
            "Epoch 176/300\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.5944 - accuracy: 0.8143 - val_loss: 1.0933 - val_accuracy: 0.7473\n",
            "Epoch 177/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.6060 - accuracy: 0.8198 - val_loss: 1.0576 - val_accuracy: 0.7418\n",
            "Epoch 178/300\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.6519 - accuracy: 0.8129 - val_loss: 1.1020 - val_accuracy: 0.7308\n",
            "Epoch 179/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.6482 - accuracy: 0.8088 - val_loss: 1.0598 - val_accuracy: 0.7473\n",
            "Epoch 180/300\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.6125 - accuracy: 0.8129 - val_loss: 1.1745 - val_accuracy: 0.7363\n",
            "Epoch 181/300\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.6910 - accuracy: 0.8074 - val_loss: 1.1539 - val_accuracy: 0.7473\n",
            "Epoch 182/300\n",
            "23/23 [==============================] - 6s 261ms/step - loss: 0.6620 - accuracy: 0.8116 - val_loss: 1.1136 - val_accuracy: 0.7363\n",
            "Epoch 183/300\n",
            "23/23 [==============================] - 4s 156ms/step - loss: 0.6608 - accuracy: 0.8019 - val_loss: 1.0590 - val_accuracy: 0.7637\n",
            "Epoch 184/300\n",
            "23/23 [==============================] - 3s 117ms/step - loss: 0.6933 - accuracy: 0.8088 - val_loss: 1.1697 - val_accuracy: 0.7198\n",
            "Epoch 185/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.7313 - accuracy: 0.8047 - val_loss: 1.1684 - val_accuracy: 0.7418\n",
            "Epoch 186/300\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 0.6615 - accuracy: 0.8267 - val_loss: 1.1039 - val_accuracy: 0.7363\n",
            "Epoch 187/300\n",
            "23/23 [==============================] - 5s 236ms/step - loss: 0.6292 - accuracy: 0.8253 - val_loss: 1.0005 - val_accuracy: 0.7418\n",
            "Epoch 188/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 0.6333 - accuracy: 0.8184 - val_loss: 1.0814 - val_accuracy: 0.7473\n",
            "Epoch 189/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6419 - accuracy: 0.8047 - val_loss: 1.0864 - val_accuracy: 0.7473\n",
            "Epoch 190/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6498 - accuracy: 0.8198 - val_loss: 1.1444 - val_accuracy: 0.7363\n",
            "Epoch 191/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6855 - accuracy: 0.8088 - val_loss: 1.0813 - val_accuracy: 0.7143\n",
            "Epoch 192/300\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.6350 - accuracy: 0.8061 - val_loss: 1.1030 - val_accuracy: 0.7527\n",
            "Epoch 193/300\n",
            "23/23 [==============================] - 3s 122ms/step - loss: 0.6154 - accuracy: 0.8253 - val_loss: 0.9871 - val_accuracy: 0.7692\n",
            "Epoch 194/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6168 - accuracy: 0.8239 - val_loss: 1.0872 - val_accuracy: 0.7473\n",
            "Epoch 195/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6140 - accuracy: 0.8253 - val_loss: 1.0553 - val_accuracy: 0.7527\n",
            "Epoch 196/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.6024 - accuracy: 0.8226 - val_loss: 1.0794 - val_accuracy: 0.7473\n",
            "Epoch 197/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6077 - accuracy: 0.8239 - val_loss: 1.1185 - val_accuracy: 0.7527\n",
            "Epoch 198/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.6938 - accuracy: 0.8006 - val_loss: 1.1025 - val_accuracy: 0.7143\n",
            "Epoch 199/300\n",
            "23/23 [==============================] - 2s 99ms/step - loss: 0.6649 - accuracy: 0.8088 - val_loss: 1.0760 - val_accuracy: 0.7692\n",
            "Epoch 200/300\n",
            "23/23 [==============================] - 3s 125ms/step - loss: 0.6177 - accuracy: 0.8212 - val_loss: 1.0682 - val_accuracy: 0.7637\n",
            "Epoch 201/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5670 - accuracy: 0.8377 - val_loss: 1.0398 - val_accuracy: 0.7418\n",
            "Epoch 202/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.5810 - accuracy: 0.8294 - val_loss: 1.0636 - val_accuracy: 0.7527\n",
            "Epoch 203/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5870 - accuracy: 0.8267 - val_loss: 1.0637 - val_accuracy: 0.7637\n",
            "Epoch 204/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5696 - accuracy: 0.8336 - val_loss: 1.0111 - val_accuracy: 0.7692\n",
            "Epoch 205/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.6242 - accuracy: 0.8336 - val_loss: 1.0599 - val_accuracy: 0.7527\n",
            "Epoch 206/300\n",
            "23/23 [==============================] - 2s 96ms/step - loss: 0.6248 - accuracy: 0.8212 - val_loss: 1.0914 - val_accuracy: 0.7582\n",
            "Epoch 207/300\n",
            "23/23 [==============================] - 3s 117ms/step - loss: 0.5719 - accuracy: 0.8363 - val_loss: 1.1098 - val_accuracy: 0.7527\n",
            "Epoch 208/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.5362 - accuracy: 0.8377 - val_loss: 1.1009 - val_accuracy: 0.7582\n",
            "Epoch 209/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5318 - accuracy: 0.8501 - val_loss: 1.0982 - val_accuracy: 0.7418\n",
            "Epoch 210/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5446 - accuracy: 0.8487 - val_loss: 1.0878 - val_accuracy: 0.7418\n",
            "Epoch 211/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5542 - accuracy: 0.8349 - val_loss: 1.0684 - val_accuracy: 0.7473\n",
            "Epoch 212/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6125 - accuracy: 0.8308 - val_loss: 1.1620 - val_accuracy: 0.7473\n",
            "Epoch 213/300\n",
            "23/23 [==============================] - 2s 102ms/step - loss: 0.7049 - accuracy: 0.8061 - val_loss: 1.1140 - val_accuracy: 0.7473\n",
            "Epoch 214/300\n",
            "23/23 [==============================] - 3s 110ms/step - loss: 0.6545 - accuracy: 0.8239 - val_loss: 1.1095 - val_accuracy: 0.7198\n",
            "Epoch 215/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.6752 - accuracy: 0.8212 - val_loss: 1.1000 - val_accuracy: 0.7527\n",
            "Epoch 216/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.6037 - accuracy: 0.8349 - val_loss: 1.0696 - val_accuracy: 0.7418\n",
            "Epoch 217/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5749 - accuracy: 0.8377 - val_loss: 1.0281 - val_accuracy: 0.7582\n",
            "Epoch 218/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5684 - accuracy: 0.8404 - val_loss: 1.0602 - val_accuracy: 0.7527\n",
            "Epoch 219/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.5930 - accuracy: 0.8267 - val_loss: 1.0662 - val_accuracy: 0.7637\n",
            "Epoch 220/300\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.5932 - accuracy: 0.8294 - val_loss: 1.1463 - val_accuracy: 0.7637\n",
            "Epoch 221/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 0.5667 - accuracy: 0.8322 - val_loss: 1.1796 - val_accuracy: 0.7582\n",
            "Epoch 222/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.5726 - accuracy: 0.8349 - val_loss: 1.1799 - val_accuracy: 0.7308\n",
            "Epoch 223/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.5758 - accuracy: 0.8459 - val_loss: 1.1095 - val_accuracy: 0.7473\n",
            "Epoch 224/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.6261 - accuracy: 0.8267 - val_loss: 1.3809 - val_accuracy: 0.7253\n",
            "Epoch 225/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.6583 - accuracy: 0.8239 - val_loss: 1.2015 - val_accuracy: 0.7418\n",
            "Epoch 226/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.6190 - accuracy: 0.8322 - val_loss: 1.1697 - val_accuracy: 0.7363\n",
            "Epoch 227/300\n",
            "23/23 [==============================] - 2s 99ms/step - loss: 0.6236 - accuracy: 0.8281 - val_loss: 1.1562 - val_accuracy: 0.7363\n",
            "Epoch 228/300\n",
            "23/23 [==============================] - 3s 131ms/step - loss: 0.6595 - accuracy: 0.8281 - val_loss: 1.1550 - val_accuracy: 0.7473\n",
            "Epoch 229/300\n",
            "23/23 [==============================] - 3s 110ms/step - loss: 0.6783 - accuracy: 0.8281 - val_loss: 1.1900 - val_accuracy: 0.7363\n",
            "Epoch 230/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.7520 - accuracy: 0.7923 - val_loss: 1.1498 - val_accuracy: 0.7363\n",
            "Epoch 231/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.7346 - accuracy: 0.7950 - val_loss: 1.1875 - val_accuracy: 0.7473\n",
            "Epoch 232/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6849 - accuracy: 0.8047 - val_loss: 1.1037 - val_accuracy: 0.7473\n",
            "Epoch 233/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.5891 - accuracy: 0.8336 - val_loss: 1.1462 - val_accuracy: 0.7527\n",
            "Epoch 234/300\n",
            "23/23 [==============================] - 2s 101ms/step - loss: 0.5638 - accuracy: 0.8514 - val_loss: 1.0706 - val_accuracy: 0.7473\n",
            "Epoch 235/300\n",
            "23/23 [==============================] - 2s 99ms/step - loss: 0.5228 - accuracy: 0.8432 - val_loss: 1.0488 - val_accuracy: 0.7637\n",
            "Epoch 236/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5183 - accuracy: 0.8501 - val_loss: 1.1525 - val_accuracy: 0.7582\n",
            "Epoch 237/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5276 - accuracy: 0.8459 - val_loss: 1.1737 - val_accuracy: 0.7527\n",
            "Epoch 238/300\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.5564 - accuracy: 0.8404 - val_loss: 1.0971 - val_accuracy: 0.7527\n",
            "Epoch 239/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5527 - accuracy: 0.8322 - val_loss: 1.1039 - val_accuracy: 0.7527\n",
            "Epoch 240/300\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 0.5973 - accuracy: 0.8294 - val_loss: 1.1599 - val_accuracy: 0.7582\n",
            "Epoch 241/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 0.5480 - accuracy: 0.8459 - val_loss: 1.1029 - val_accuracy: 0.7473\n",
            "Epoch 242/300\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.5931 - accuracy: 0.8363 - val_loss: 1.1825 - val_accuracy: 0.7363\n",
            "Epoch 243/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5771 - accuracy: 0.8404 - val_loss: 1.1317 - val_accuracy: 0.7418\n",
            "Epoch 244/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5690 - accuracy: 0.8322 - val_loss: 1.1121 - val_accuracy: 0.7582\n",
            "Epoch 245/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.6329 - accuracy: 0.8157 - val_loss: 1.1872 - val_accuracy: 0.7582\n",
            "Epoch 246/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.7214 - accuracy: 0.8033 - val_loss: 1.2736 - val_accuracy: 0.7308\n",
            "Epoch 247/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.6526 - accuracy: 0.8267 - val_loss: 1.2081 - val_accuracy: 0.7473\n",
            "Epoch 248/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.5734 - accuracy: 0.8418 - val_loss: 1.1453 - val_accuracy: 0.7418\n",
            "Epoch 249/300\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.5590 - accuracy: 0.8363 - val_loss: 1.1143 - val_accuracy: 0.7308\n",
            "Epoch 250/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.5306 - accuracy: 0.8501 - val_loss: 1.0680 - val_accuracy: 0.7527\n",
            "Epoch 251/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5578 - accuracy: 0.8418 - val_loss: 1.2030 - val_accuracy: 0.7582\n",
            "Epoch 252/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5559 - accuracy: 0.8322 - val_loss: 1.0881 - val_accuracy: 0.7527\n",
            "Epoch 253/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5812 - accuracy: 0.8446 - val_loss: 1.1945 - val_accuracy: 0.7418\n",
            "Epoch 254/300\n",
            "23/23 [==============================] - 2s 88ms/step - loss: 0.5693 - accuracy: 0.8391 - val_loss: 1.1123 - val_accuracy: 0.7527\n",
            "Epoch 255/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.5255 - accuracy: 0.8487 - val_loss: 1.1816 - val_accuracy: 0.7582\n",
            "Epoch 256/300\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.5131 - accuracy: 0.8556 - val_loss: 1.1051 - val_accuracy: 0.7582\n",
            "Epoch 257/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.5265 - accuracy: 0.8459 - val_loss: 1.1022 - val_accuracy: 0.7473\n",
            "Epoch 258/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5047 - accuracy: 0.8611 - val_loss: 1.1081 - val_accuracy: 0.7527\n",
            "Epoch 259/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.5255 - accuracy: 0.8404 - val_loss: 1.1391 - val_accuracy: 0.7308\n",
            "Epoch 260/300\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 0.5389 - accuracy: 0.8459 - val_loss: 1.1841 - val_accuracy: 0.7253\n",
            "Epoch 261/300\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.5599 - accuracy: 0.8459 - val_loss: 1.1559 - val_accuracy: 0.7527\n",
            "Epoch 262/300\n",
            "23/23 [==============================] - 2s 108ms/step - loss: 0.5304 - accuracy: 0.8501 - val_loss: 1.2050 - val_accuracy: 0.7363\n",
            "Epoch 263/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.5686 - accuracy: 0.8459 - val_loss: 1.1640 - val_accuracy: 0.7418\n",
            "Epoch 264/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5396 - accuracy: 0.8487 - val_loss: 1.1237 - val_accuracy: 0.7582\n",
            "Epoch 265/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5086 - accuracy: 0.8542 - val_loss: 1.2399 - val_accuracy: 0.7198\n",
            "Epoch 266/300\n",
            "23/23 [==============================] - 2s 83ms/step - loss: 0.5795 - accuracy: 0.8487 - val_loss: 1.2387 - val_accuracy: 0.7418\n",
            "Epoch 267/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5721 - accuracy: 0.8514 - val_loss: 1.1724 - val_accuracy: 0.7527\n",
            "Epoch 268/300\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.5322 - accuracy: 0.8487 - val_loss: 1.1000 - val_accuracy: 0.7418\n",
            "Epoch 269/300\n",
            "23/23 [==============================] - 2s 109ms/step - loss: 0.5089 - accuracy: 0.8514 - val_loss: 1.1705 - val_accuracy: 0.7473\n",
            "Epoch 270/300\n",
            "23/23 [==============================] - 2s 87ms/step - loss: 0.5248 - accuracy: 0.8446 - val_loss: 1.1829 - val_accuracy: 0.7473\n",
            "Epoch 271/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5283 - accuracy: 0.8514 - val_loss: 1.1860 - val_accuracy: 0.7418\n",
            "Epoch 272/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.5871 - accuracy: 0.8404 - val_loss: 1.4036 - val_accuracy: 0.7143\n",
            "Epoch 273/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.6782 - accuracy: 0.8281 - val_loss: 1.1783 - val_accuracy: 0.7418\n",
            "Epoch 274/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5827 - accuracy: 0.8473 - val_loss: 1.2172 - val_accuracy: 0.7527\n",
            "Epoch 275/300\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.5218 - accuracy: 0.8459 - val_loss: 1.1027 - val_accuracy: 0.7473\n",
            "Epoch 276/300\n",
            "23/23 [==============================] - 2s 103ms/step - loss: 0.6037 - accuracy: 0.8308 - val_loss: 1.1241 - val_accuracy: 0.7582\n",
            "Epoch 277/300\n",
            "23/23 [==============================] - 2s 88ms/step - loss: 0.6437 - accuracy: 0.8102 - val_loss: 1.2308 - val_accuracy: 0.7418\n",
            "Epoch 278/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.6268 - accuracy: 0.8184 - val_loss: 1.1267 - val_accuracy: 0.7473\n",
            "Epoch 279/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.6249 - accuracy: 0.8267 - val_loss: 1.2831 - val_accuracy: 0.7143\n",
            "Epoch 280/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.6612 - accuracy: 0.8253 - val_loss: 1.2298 - val_accuracy: 0.7527\n",
            "Epoch 281/300\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.6257 - accuracy: 0.8377 - val_loss: 1.2035 - val_accuracy: 0.7527\n",
            "Epoch 282/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.5245 - accuracy: 0.8459 - val_loss: 1.1123 - val_accuracy: 0.7582\n",
            "Epoch 283/300\n",
            "23/23 [==============================] - 2s 107ms/step - loss: 0.4941 - accuracy: 0.8583 - val_loss: 1.0921 - val_accuracy: 0.7527\n",
            "Epoch 284/300\n",
            "23/23 [==============================] - 2s 98ms/step - loss: 0.5097 - accuracy: 0.8473 - val_loss: 1.1542 - val_accuracy: 0.7418\n",
            "Epoch 285/300\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 0.4946 - accuracy: 0.8542 - val_loss: 1.2238 - val_accuracy: 0.7363\n",
            "Epoch 286/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.5388 - accuracy: 0.8404 - val_loss: 1.1798 - val_accuracy: 0.7363\n",
            "Epoch 287/300\n",
            "23/23 [==============================] - 2s 81ms/step - loss: 0.5375 - accuracy: 0.8459 - val_loss: 1.2016 - val_accuracy: 0.7418\n",
            "Epoch 288/300\n",
            "23/23 [==============================] - 2s 84ms/step - loss: 0.5525 - accuracy: 0.8487 - val_loss: 1.1441 - val_accuracy: 0.7582\n",
            "Epoch 289/300\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.5098 - accuracy: 0.8514 - val_loss: 1.1651 - val_accuracy: 0.7527\n",
            "Epoch 290/300\n",
            "23/23 [==============================] - 2s 105ms/step - loss: 0.5149 - accuracy: 0.8501 - val_loss: 1.1601 - val_accuracy: 0.7582\n",
            "Epoch 291/300\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.5684 - accuracy: 0.8487 - val_loss: 1.2043 - val_accuracy: 0.7582\n",
            "Epoch 292/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.6219 - accuracy: 0.8308 - val_loss: 1.2540 - val_accuracy: 0.7473\n",
            "Epoch 293/300\n",
            "23/23 [==============================] - 2s 82ms/step - loss: 0.5822 - accuracy: 0.8418 - val_loss: 1.2553 - val_accuracy: 0.7527\n",
            "Epoch 294/300\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.5777 - accuracy: 0.8514 - val_loss: 1.1554 - val_accuracy: 0.7473\n",
            "Epoch 295/300\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.5374 - accuracy: 0.8459 - val_loss: 1.1862 - val_accuracy: 0.7308\n",
            "Epoch 296/300\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.5465 - accuracy: 0.8446 - val_loss: 1.1951 - val_accuracy: 0.7253\n",
            "Epoch 297/300\n",
            "23/23 [==============================] - 2s 104ms/step - loss: 0.5642 - accuracy: 0.8377 - val_loss: 1.1909 - val_accuracy: 0.7418\n",
            "Epoch 298/300\n",
            "23/23 [==============================] - 2s 97ms/step - loss: 0.5277 - accuracy: 0.8569 - val_loss: 1.1743 - val_accuracy: 0.7253\n",
            "Epoch 299/300\n",
            "23/23 [==============================] - 2s 85ms/step - loss: 0.4882 - accuracy: 0.8638 - val_loss: 1.1479 - val_accuracy: 0.7637\n",
            "Epoch 300/300\n",
            "23/23 [==============================] - 2s 86ms/step - loss: 0.4936 - accuracy: 0.8556 - val_loss: 1.1758 - val_accuracy: 0.7418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(XKey_test,yKey_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxjiPeKYU21Q",
        "outputId": "93432c39-c7d0-44ce-f6ed-05f1f6b945c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 46ms/step - loss: 1.0725 - accuracy: 0.7862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0725456476211548, 0.7861841917037964]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to a file\n",
        "model.save('PoseStream1.h5')"
      ],
      "metadata": {
        "id": "iRY-fmFDU5oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmaxRGB = RGBmodel.predict(X_trainRGB)\n",
        "softmaxPose = Posemodel.predict(XKey_train)"
      ],
      "metadata": {
        "id": "Yn8GnDFQ4sDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Combine the softmax outputs by taking the average of their values\n",
        "combined_softmax = (softmaxRGB*0.7 + softmaxPose*0.3) \n",
        "\n",
        "# Generate some example ground truth labels\n",
        "actualValues = Ytrain\n",
        "\n",
        "# Convert the combined softmax probabilities to predicted labels\n",
        "predicted_labels = np.argmax(combined_softmax)\n",
        "\n",
        "# Compute the accuracy of the predictions\n",
        "accuracy = np.mean(predicted_labels == actualValues)\n",
        "\n",
        "# Print the results\n",
        "print(\"Combined softmax probabilities:\", combined_softmax)\n",
        "print(\"Ground truth labels:\", actualValues)\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "ShtiENuz4qhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras import initializers\n",
        "from keras.layers import Conv3D, MaxPooling3D,Dense,ZeroPadding3D,Flatten,Activation,BatchNormalization,RandomFlip,RandomRotation,Rescaling\n",
        "from keras.models import load_model\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/MyDrive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os,cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data_path = '../MyDrive/MyDrive/Dataset'\n",
        "\n",
        "\n",
        "labels=[]\n",
        "for folder in os.listdir(data_path):\n",
        "    labels.append(folder)\n",
        "labels.sort() #len = 107\n",
        "\n",
        "train_videos=[]\n",
        "train_labels=[]\n",
        "train_keypoints = []\n",
        "import traceback\n",
        "import random\n",
        "\n",
        "num = 1\n",
        "\n",
        "for i,folder in enumerate(labels):\n",
        "  try:\n",
        "    for video in os.listdir(data_path+'/'+folder):\n",
        "      print(num)\n",
        "      num+=1\n",
        "      video = os.path.join(data_path+'/'+folder+'/'+video)\n",
        "      # Open the video file\n",
        "      cap = cv2.VideoCapture(video)\n",
        "\n",
        "      # Get the total number of frames in the video\n",
        "      total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "      # Select a random starting frame number\n",
        "      start_frame = random.randint(0, total_frames - 16)\n",
        "\n",
        "      # Set the number of frames to be selected\n",
        "      num_frames = 16\n",
        "\n",
        "      # Set the frame number to start with\n",
        "      cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "      # Loop through the frames and save them\n",
        "      frames = []\n",
        "      keypoints = []\n",
        "      for j in range(num_frames):\n",
        "          ret, image = cap.read()\n",
        "          if ret:\n",
        "            frames.append(cv2.resize(image,(112,112)))\n",
        "            kk = getKeyPointsforFrame(image)\n",
        "            keypoints.append(kk)\n",
        "\n",
        "      # Release the video file\n",
        "      cap.release()\n",
        "\n",
        "\n",
        "      train_videos.append(frames)\n",
        "\n",
        "      train_keypoints.append(CentralisedKeypoints2(keypoints))\n",
        "      train_labels.append(i)\n",
        "      # if(num>2):\n",
        "      #    break\n",
        "\n",
        "  except Exception:\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "NZL0o1jOFn_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmaxRGB = RGBmodel.predict(X_trainRGB)\n",
        "softmaxPose = Posemodel.predict(XKey_train)"
      ],
      "metadata": {
        "id": "VQ0mPnOAFtDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Combine the softmax outputs by taking the average of their values\n",
        "combined_softmax = (softmaxRGB*0.7 + softmaxPose*0.3) \n",
        "\n",
        "# Generate some example ground truth labels\n",
        "actualValues = yKey_train\n",
        "\n",
        "# Convert the combined softmax probabilities to predicted labels\n",
        "predicted_labels = np.argmax(combined_softmax)\n",
        "\n",
        "# Compute the accuracy of the predictions\n",
        "accuracy = np.mean(predicted_labels == actualValues)\n",
        "\n",
        "# Print the results\n",
        "print(\"Combined softmax probabilities:\", combined_softmax)\n",
        "print(\"Ground truth labels:\", actualValues)\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "jNsDFrDDKETo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['Adhomukhasvanasana',\n",
        "  'Ardhachakrasana',\n",
        "  'Bhujangasana',\n",
        "  'Dhanurasana',\n",
        "  'Marjariasana',\n",
        "  'Padahastasana',\n",
        "  'Padmasana',\n",
        "  'Pawanmuktasana',\n",
        "  'Phalakasana',\n",
        "  'Sarvangasana',\n",
        "  'Sashankasana',\n",
        "  'Setubandhasana',\n",
        "  'Shavasana',\n",
        "  'Tadasana',\n",
        "  'Trikonasana',\n",
        "  'Ustrasana',\n",
        "  'Vakrasana',\n",
        "  'Virbhadrasana1',\n",
        "  'Virbhadrasana2',\n",
        "  'Vrikshasana']\n",
        "  \n",
        "for folder in os.listdir(data_path):\n",
        "    labels.append(folder)\n",
        "labels.sort()\n",
        "\n",
        "def predictYogaPose(video,keypoints):\n",
        "  softmaxRGB = RGBmodel.predict(video)\n",
        "  softmaxPose = Posemodel.predict(keypoints)\n",
        "  combined_softmax = (softmaxRGB*0.7 + softmaxPose*0.3) \n",
        "\n",
        "  predicted_labels = np.argmax(combined_softmax)\n",
        "\n",
        "  return labels[predicted_labels]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bRr9sLeVNhS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "data_path = './Videos'\n",
        "\n",
        "labels=[]\n",
        "for folder in os.listdir(data_path):\n",
        "    labels.append(folder)\n",
        "labels.sort() #len = 107\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IRudBfvPJW6",
        "outputId": "d68627c2-1255-4e5b-9831-be8af9fcdce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adhomukhasvanasana',\n",
              " 'Ardhachakrasana',\n",
              " 'Bhujangasana',\n",
              " 'Dhanurasana',\n",
              " 'Marjariasana',\n",
              " 'Padahastasana',\n",
              " 'Padmasana',\n",
              " 'Pawanmuktasana',\n",
              " 'Phalakasana',\n",
              " 'Sarvangasana',\n",
              " 'Sashankasana',\n",
              " 'Setubandhasana',\n",
              " 'Shavasana',\n",
              " 'Tadasana',\n",
              " 'Trikonasana',\n",
              " 'Ustrasana',\n",
              " 'Vakrasana',\n",
              " 'Virbhadrasana1',\n",
              " 'Virbhadrasana2',\n",
              " 'Vrikshasana']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RGBmodel = load_model('RGBStream.h5')\n",
        "Posemodel = load_model('PoseStream.h5')\n",
        "\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "video = []\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "  \n",
        "  video.append(frame)\n",
        "\n",
        "  if(len(video)==16):\n",
        "    keypoints = []\n",
        "    for image in video:\n",
        "      keypoints.append(getKeyPointsforFrame(image))\n",
        "\n",
        "    keypoints = CentralisedKeypoints2(keypoints)\n",
        "\n",
        "    if(keypoints == None):\n",
        "      print(\"video not visible\")\n",
        "\n",
        "    yogaPose = predictYogaPose(video,keypoints)\n",
        "\n"
      ],
      "metadata": {
        "id": "xbxIXP0yNIgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}