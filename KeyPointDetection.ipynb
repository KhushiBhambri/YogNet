{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyON1QMbvJP8H44iRFFTKnfT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# import sys\n","# sys.path.append('/content/drive/MyDrive/Major_Project_Cse')\n","\n","%cd \"/content/drive/MyDrive/Major_Project_Cse\""],"metadata":{"id":"q9APBV-UaPei"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87sjJhE0ZrJ4","executionInfo":{"status":"ok","timestamp":1681050277883,"user_tz":-330,"elapsed":17215,"user":{"displayName":"Khushi Bhambri","userId":"11886784607536656021"}},"outputId":"56a003af-c16e-4541-a921-492ad02d80e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.9.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.6/33.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.22.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (from mediapipe) (4.7.0.72)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.20.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (22.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from mediapipe) (23.3.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (23.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (4.39.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mediapipe) (1.0.7)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.9.2.1\n","Downloading model to /usr/local/lib/python3.9/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n"]}],"source":["!pip install mediapipe\n","import cv2\n","import mediapipe as mp\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","\n","mp_pose = mp.solutions.pose\n","\n","# Setup the Pose function for images - independently for the images standalone processing.\n","pose_image = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.8,model_complexity=2)\n","\n","# Setup the Pose function for videos - for video processing.\n","pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7,\n","                          min_tracking_confidence=0.7)\n","\n","# Initialize mediapipe drawing class - to draw the landmarks points.\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles"]},{"cell_type":"code","source":["def mpPoseImg(image_pose, pose=pose_image, draw=False, display=False):\n","    \n","    annotated_image = image_pose.copy()\n","    \n","    image_in_RGB = cv2.cvtColor(image_pose, cv2.COLOR_BGR2RGB)\n"," \n","    \n","    results = pose.process(image_in_RGB)\n","\n","    if results.pose_landmarks and draw:    \n","      mp_drawing.draw_landmarks(image=annotated_image,landmark_list=results.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n","                                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n","\n","\n","        # mp_drawing.draw_landmarks(image=original_image, landmark_list=resultant.pose_landmarks,connections=mp_pose.POSE_CONNECTIONS,\n","        #                           landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255,255,255),thickness=3, circle_radius=3),\n","        #                           connection_drawing_spec=mp_drawing.DrawingSpec(color=(49,125,237),thickness=2, circle_radius=2))\n","\n","    if display:\n","            \n","            # plt.figure(figsize=[22,22])\n","            # plt.subplot(121);plt.imshow(image_pose[:,:,::-1]);plt.title(\"Input Image\");plt.axis('off');\n","            # plt.subplot(122);plt.imshow(annotated_image[:,:,::-1]);plt.title(\"Pose detected Image\");plt.axis('off');\n","            cv2_imshow(annotated_image)\n","            return results\n","\n","    else:\n","        \n","        return annotated_image,results"],"metadata":{"id":"eoYlpMSLZx1_","executionInfo":{"status":"ok","timestamp":1681050277886,"user_tz":-330,"elapsed":19,"user":{"displayName":"Khushi Bhambri","userId":"11886784607536656021"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["numOfKeypoints = 34\n","def getKeyPointsforFrame(frame):\n","  img,results = mpPoseImg(frame)\n","  keypoints = [[None,None] for _ in range(numOfKeypoints)]\n","  if results.pose_landmarks == None:\n","    return keypoints\n","    \n","  landmarks = results.pose_landmarks\n","  for i in range(numOfKeypoints-2):\n","     mark = landmarks.landmark[i]\n","     keypoints[i][0]=mark.x\n","     keypoints[i][1]=mark.y\n","  #------------------------------------------------------------------------------------------------\n","  try:\n","    # MID HIP COORDINATES\n","      left_hip_index = 23\n","      right_hip_index = 24\n","      Mid_hip_x =  (keypoints[left_hip_index][0]+keypoints[right_hip_index][0])/2\n","      Mid_hip_y =(keypoints[left_hip_index][1]+keypoints[right_hip_index][1])/2\n","      # keypoints.append([Mid_hip_x,Mid_hip_y])\n","      keypoints[32][0]=Mid_hip_x\n","      keypoints[32][1]=Mid_hip_y\n","                          \n","  except:\n","      pass\n","      \n","  #------------------------------------------------------------------------------------------------\n","  try:\n","    # NECK COORDINATES\n","      left_shoulder_index = 11\n","      right_shoulder_index = 12\n","      Neck_x =  (keypoints[left_shoulder_index][0]+keypoints[right_shoulder_index][0])/2\n","      Neck_y =(keypoints[left_shoulder_index][1]+keypoints[right_shoulder_index][1])/2\n","      # keypoints.append([Neck_x,Neck_y])\n","      keypoints[33][0]=Neck_x\n","      keypoints[33][1]=Neck_y\n","                          \n","  except:\n","      pass\n","\n","  #------------------------------------------------------------------------------------------------\n","     \n","  return keypoints"],"metadata":{"id":"0NC8QQSAZ1EK","executionInfo":{"status":"ok","timestamp":1681050350837,"user_tz":-330,"elapsed":3,"user":{"displayName":"Khushi Bhambri","userId":"11886784607536656021"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["imagePath='Images/yoga.jpg'\n","img = cv2.imread(imagePath)\n","getKeyPointsforFrame(img)"],"metadata":{"id":"LeF6j2mYauFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","import pandas as pd\n","# import tensorflow as tf\n","import os,cv2\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","data_path = './Videos'\n","\n","\n","\n","labels=[]\n","for folder in os.listdir(data_path):\n","    labels.append(folder)\n","labels.sort() #len = 107\n","\n","\n","train_videos=[]\n","train_labels=[]\n","train_keypoints = []\n","import traceback\n","import random\n","\n","num = 1\n","\n","for i,folder in enumerate(labels):\n","  try:\n","    for video in os.listdir(data_path+'/'+folder):\n","      print(num)\n","      num+=1\n","      video = os.path.join(data_path+'/'+folder+'/'+video)\n","      # Open the video file\n","      cap = cv2.VideoCapture(video)\n","\n","      # Get the total number of frames in the video\n","      total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","      # Select a random starting frame number\n","      start_frame = random.randint(0, total_frames - 16)\n","\n","      # Set the number of frames to be selected\n","      num_frames = 16\n","\n","      # Set the frame number to start with\n","      cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n","\n","      # Loop through the frames and save them\n","      frames = []\n","      keypoints = []\n","      for j in range(num_frames):\n","          ret, image = cap.read()\n","          if ret:\n","            frames.append(cv2.resize(image,(112,112)))\n","            kk = getKeyPointsforFrame(image)\n","            keypoints.append(kk)\n","\n","      # Release the video file\n","      cap.release()\n","\n","\n","      # train_videos.append(frames)\n","      train_keypoints.append(keypoints)\n","      train_labels.append(i)\n","      # if(num>2):\n","      #    break\n","\n","  except Exception:\n","    traceback.print_exc()\n"],"metadata":{"id":"v9HKp1aQaK3-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# create a DataFrame to store the data\n","data = pd.DataFrame({'keypoints': train_keypoints, 'label': train_labels})\n","\n","# save the DataFrame to a CSV file\n","data.to_csv('train_data.csv', index=False)"],"metadata":{"id":"8gKU3EmNalFy"},"execution_count":null,"outputs":[]}]}